{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "XAXL1kQOwWSL",
    "outputId": "a871d421-80cb-4cd9-a6fa-24b70735b1c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  train_posters.zip\n",
      "replace train_posters/100114.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: Archive:  test_posters.zip\n",
      "replace test_posters/100388.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ],
   "source": [
    "#!unzip train_posters.zip\n",
    "#!unzip test_posters.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oTBjtepwwcek"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read csv data\n",
    "# Reorder the labels to match the order of the images\n",
    "\n",
    "csv_data = pd.read_csv('train_data.csv').as_matrix()\n",
    "\n",
    "csv_data = csv_data[csv_data[:,1].argsort()] # csv_data[:,1].argsort() returns indices that sort movies by imdb # \n",
    "genres = csv_data[:,-1]\n",
    "\n",
    "\n",
    "test_data_csv = pd.read_csv('test_data.csv').as_matrix()\n",
    "\n",
    "# One-hot encode genres column\n",
    "\n",
    "train_labels = to_categorical(np.array(genres))\n",
    "#print(\"Label for first training example: {}\".format(genres[0]))\n",
    "#print(\"One-hot encoded label for first training example: {}\".format(train_labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ORRJkZ1CykS-"
   },
   "outputs": [],
   "source": [
    "train_data = 'train_posters'\n",
    "test_data = 'test_posters'\n",
    "\n",
    "def preprocess_training_data():\n",
    "    train_images = []\n",
    "    image_num = 0\n",
    "\n",
    "    for ind,i in enumerate(csv_data[:,1]):\n",
    "\n",
    "        path = os.path.join(train_data,str(i) + \".jpg\")\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (64,64))\n",
    "\n",
    "        train_images.append(np.array(img)/255)\n",
    "    return train_images\n",
    "\n",
    "\n",
    "def preprocess_test_data():\n",
    "    test_images = []\n",
    "    for ind,i in enumerate(test_data_csv[:,1]):\n",
    "\n",
    "        path = os.path.join(test_data,str(i) + \".jpg\")\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (64,64))\n",
    "        test_images.append(np.array(img)/255)\n",
    "            \n",
    "    return test_images\n",
    "    \n",
    "preprocessed_train = preprocess_training_data()\n",
    "preprocessed_test = preprocess_test_data()\n",
    "\n",
    "\n",
    "x_train = np.array(preprocessed_train).reshape(-1,64,64,1)\n",
    "y_train = train_labels\n",
    "\n",
    "x_test = np.array(preprocessed_test).reshape(-1,64,64,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z868-lyF3u-1"
   },
   "outputs": [],
   "source": [
    "# Display training example #1371 Death Note, a well-acclaimed Hollywood adaption of the Death Note anime (jk)\n",
    "# Display movie poster and associated label and title\n",
    "\n",
    "# Feel free to change the train_ind and see how the preprocessing affect the images\n",
    "train_ind = 1371\n",
    "plt.imshow(preprocessed_train[train_ind])\n",
    "print(csv_data[:,1][train_ind])\n",
    "print(y_train[train_ind])\n",
    "print(csv_data[:,(3,4,5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0qcz9rPd5fzF"
   },
   "outputs": [],
   "source": [
    "# Displaying test example #200 \n",
    "# Remember there is no genre label or title associated with this image\n",
    "# We are trying to predict the labels! \n",
    "\n",
    "plt.imshow(preprocessed_test[200])\n",
    "print(\"Test example #200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tve3Cvci65yS"
   },
   "outputs": [],
   "source": [
    "# CNN\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import InputLayer, Conv2D, MaxPool2D, Flatten, Dense\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(InputLayer(input_shape=[64,64,1]))\n",
    "model.add(Conv2D(filters=32,kernel_size=(3,3),padding='same',activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2),padding='same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(x=x_train, y=y_train, epochs=8, batch_size=50)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jysPtSDWNA-U"
   },
   "outputs": [],
   "source": [
    "# cnn prediction (dec values)\n",
    "\n",
    "model.save(\"movie_classifier.h5py\")\n",
    "cnn_predict = model.predict(x_test, batch_size=32, verbose=0, steps=None)\n",
    "cnn_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "colab_type": "code",
    "id": "DbMj9_hkDdGz",
    "outputId": "e1f0f90b-1f6c-4933-badb-8672dd8b7d45"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-06db124aad25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgenre_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# creating odd list of K for KNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'genres' is not defined"
     ]
    }
   ],
   "source": [
    "# Using cross validation to find the best k for KNN\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "genre_list = genres.tolist()\n",
    "\n",
    "# creating odd list of K for KNN\n",
    "klist = list(range(1,50))\n",
    "\n",
    "# subsetting just the odd ones\n",
    "neighbors = filter(lambda x: x % 2 != 0, klist)\n",
    "\n",
    "# empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "\n",
    "# perform 10-fold cross validation\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, csv_data[:,(4,5)], genre_list, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "#print(cv_scores)\n",
    "#print(\"cv_scores mean:{}\".format(np.mean(cv_scores)))\n",
    "print(\"k best =\",cv_scores.index(max(cv_scores)))\n",
    "print(\"accuracy =\",cv_scores[23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "colab_type": "code",
    "id": "qBSPRJWGwbk7",
    "outputId": "48df3e30-32ba-4288-8c69-b67ca9fb8955"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-876ca6d461c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgenre_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# KNN for runtime and score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'genres' is not defined"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "genre_list = genres.tolist()\n",
    "\n",
    "# KNN for runtime and score\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=23)\n",
    "neigh.fit(csv_data[:,(4,5)], genre_list)\n",
    "neigh_predict = neigh.predict(test_data_csv[:,(4,5)])  # neigh_predict is the KNN prediction for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_NgoXJEScn7p"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "genre_list = genres.tolist()\n",
    "\n",
    "#linear\n",
    "#svclassifier = SVC(kernel='linear',C=4) \n",
    "\n",
    "#polynomial \n",
    "#svclassifier = SVC(kernel='poly', degree=3)\n",
    "\n",
    "#gaussian meh\n",
    "#svclassifier = SVC(kernel='rbf', C=1, gamma=0.1) \n",
    "\n",
    "#sigmoid not good\n",
    "#svclassifier = SVC(kernel='sigmoid')\n",
    "\n",
    "#svm_scores = cross_val_score(svclassifier, csv_data[:,(3,4,5)], genre_list, cv=10, scoring='accuracy')\n",
    "#print(svm_scores)\n",
    "\n",
    "svclassifier.fit(csv_data[:,(3,4,5)], genre_list) \n",
    "y_svm = svclassifier.predict(test_data_csv[:,(3,4,5)]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Predictions\n",
    "# Decide not to use Naive Bayes because it made the accuracy worse\n",
    "# COMBINE CNN, KNN, and SVM\n",
    "\n",
    "one_hot1 = to_categorical(neigh_predict)*0.4 # one-hot encode neigh_predict and multiply by 0.4 (maybe a diff value will work better, idk)\n",
    "one_hot2 = to_categorical(y_svm)*0.7\n",
    "predict = one_hot1 + one_hot2 + cnn_predict # Add one_hot and predict (output from the conv neural network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udCcVw7hURk1"
   },
   "outputs": [],
   "source": [
    "# write test predictions in csv file\n",
    "\n",
    "from google.colab import files\n",
    "import numpy as np\n",
    "import csv\n",
    "predict_class = np.argmax(predict,axis=1)\n",
    "with open('out.csv','w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for val in predict_class:\n",
    "        writer.writerows(str(val))    \n",
    "f.close()\n",
    "\n",
    "files.download(\"out.csv\") # download csv file of test predictions"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Shotaro_BigDataEnergy.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
